经常刷历史数据，工作总结一下


1.
applicationContext-service.xml  配置spring 框架 定时任务 触发定时任务

    <bean id="jdFirstTimeRefreshThreadExectorTask" class="org.springframework.scheduling.concurrent.ScheduledExecutorTask">
        <property name="runnable" ref="jdFirstTimeRefreshThreadExector"/>
        <!--&lt;!&ndash; 容器加载30秒后开始执行 &ndash;&gt;-->
        <property name="delay" value="10000"/>
        <!--&lt;!&ndash; 每次任务间隔1秒&ndash;&gt;-->
        <property name="period" value="1000"/>
    </bean>

    <bean id="springScheduledExecutorFactoryBean"
          class="org.springframework.scheduling.concurrent.ScheduledExecutorFactoryBean">
        <property name="scheduledExecutorTasks">
            <list>
                <ref bean="jdFirstTimeRefreshThreadExectorTask"/>
            </list>
        </property>
    </bean>
</


2. 一个定时任务，细分一个大区间的数据，每个小区间教给一个线程去批量处理。    
  线程栅栏

package com.yit.datamigration.exector;

import com.yit.common.utils.cache.CacheService;
import com.yit.datamigration.dao.dto.LogisticsInfoDTOWithBLOBs;
import com.yit.datamigration.dao.mapper.SubOrderSkuMapper;
import com.yit.datamigration.dao.mapper.LogisticsInfoMapper;
import com.yit.datamigration.thread.JdFirstTimeRefreshThread;
import com.yit.orders.api.inner.QueryOrderService;
import org.apache.commons.collections.CollectionUtils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;
import org.springframework.stereotype.Component;

import javax.annotation.Resource;
import java.util.List;
import java.util.TimerTask;
import java.util.concurrent.CountDownLatch;

/**
 * lixiang create at 上午10:49 2018/7/17
 **/
@Component("jdFirstTimeRefreshThreadExector")
public class JdFirstTimeRefreshThreadExector extends TimerTask {

    private final static Logger LOGGER = LoggerFactory.getLogger(JdFirstTimeRefreshThreadExector.class);

    @Resource
    private CacheService cacheService;
    @Resource
    private ThreadPoolTaskExecutor taskExecutor;
    @Resource
    private LogisticsInfoMapper logisticsInfoMapper;

    private static final String NAMESPACE = "JdFirstTimeRefreshThreadExector";
    private static final String KEY = "yitiao_logistics_info_id_index_5";
    private static final int PAGE_SIZE = 500;
    private static final int PROCESS_PAGE_NUM = 10;

    private static final int MAX_ID = ;  // logistics-service 上线后的某一条数据ID
    private static final int MIN_ID = 6880609; // 2018-08-31 的某一条数据ID


    private final CountDownLatch countDownLatch = new CountDownLatch(PROCESS_PAGE_NUM);

    /**
     * The action to be performed by this timer task.
     */
    @Override
    public void run() {
        int maxIndexId = MAX_ID;
        Integer currentId = cacheService.get(NAMESPACE, KEY);
        if (currentId == null) {
            currentId = MAX_ID;
        }
        if (currentId <= MIN_ID) {
            LOGGER.info("JdFirstTimeRefreshThreadExector  数据已处理完");
            return;
        }

        LOGGER.info("maxIndexId = {}  currentId = {} ", maxIndexId, currentId);
        // 10 * 500
        for (int i = 0; i < PROCESS_PAGE_NUM; i++) {
            int maxId = currentId - i * PAGE_SIZE;
            int minId = currentId - (i + 1) * PAGE_SIZE;
            LOGGER.info("minId = {}  maxId = {} ", minId, maxId);
            List<LogisticsInfoDTOWithBLOBs> logisticsInfos = logisticsInfoMapper.getLogisticsInfo(minId, maxId);
            if (CollectionUtils.isNotEmpty(logisticsInfos)) {
//                LOGGER.info("logisticsInfos.size() = {}",logisticsInfos.size());
                taskExecutor.execute(new JdFirstTimeRefreshThread(countDownLatch, logisticsInfos, logisticsInfoMapper));
            } else {
                countDownLatch.countDown();
            }
        }

        try {
            countDownLatch.await();
            currentId = currentId - PROCESS_PAGE_NUM * PAGE_SIZE;
            cacheService.set(NAMESPACE, KEY, 864000, currentId);
        } catch (InterruptedException e) {
            LOGGER.error("JdFirstTimeRefreshThreadExector error", e);
        }
    }
}


3.  核心点，数据要批量处理， 注意数据库链接资源  使用 update case when 实现一次更新多行数据
    countDownLatch.countDown();


package com.yit.datamigration.thread;

import com.alibaba.fastjson.JSON;
import com.yit.datamigration.dao.dto.LogisticsInfoDTOWithBLOBs;
import com.yit.datamigration.dao.mapper.LogisticsInfoMapper;
import com.yit.datamigration.exector.entity.KuaiDaoYunKLogisticsEntity;
import org.apache.commons.collections.CollectionUtils;
import org.apache.commons.lang3.StringUtils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Comparator;
import java.util.Date;
import java.util.List;
import java.util.concurrent.CountDownLatch;
import java.util.stream.Collectors;

/**
 * create at 11:01 AM 2019/3/20
 *
 * @author lixiang
 **/
public class JdFirstTimeRefreshThread implements Runnable {


    private final static Logger LOGGER = LoggerFactory.getLogger(JdFirstTimeRefreshThread.class);

    private CountDownLatch countDownLatch;
    private List<LogisticsInfoDTOWithBLOBs> logisticsInfos;
    private LogisticsInfoMapper logisticsInfoMapper;

    public JdFirstTimeRefreshThread(CountDownLatch countDownLatch, List<LogisticsInfoDTOWithBLOBs> logisticsInfos, LogisticsInfoMapper logisticsInfoMapper) {
        this.countDownLatch = countDownLatch;
        this.logisticsInfos = logisticsInfos;
        this.logisticsInfoMapper = logisticsInfoMapper;
    }

    @Override
    public void run() {
        List<LogisticsInfoDTOWithBLOBs> toUpdateList = new ArrayList<>();
        for (LogisticsInfoDTOWithBLOBs info : logisticsInfos) {
            if (StringUtils.isNotBlank(info.getLogisticsInfo()) && !"[]".equals(info.getLogisticsInfo())) {
                List<KuaiDaoYunKLogisticsEntity> list = JSON.parseArray(info.getLogisticsInfo(), KuaiDaoYunKLogisticsEntity.class);
                String firstInfoTime = parseFirstInfoTime(list, info.getLogisticsCompanyCode());
                if (StringUtils.isNotBlank(firstInfoTime)) {
                    Date date = stringToDate(firstInfoTime, "yyyy-MM-dd HH:mm:ss");
                    LogisticsInfoDTOWithBLOBs temp = new LogisticsInfoDTOWithBLOBs();
                    temp.setId(info.getId());
                    temp.setFirstInfoTime(date);
                    toUpdateList.add(temp);
//                    LOGGER.info("company = {}, firstInfoTime  = {} id = {}  info.getLogisticsInfo() = {}", info.getLogisticsCompanyCode() ,firstInfoTime, info.getId(), info.getLogisticsInfo() );

                }
            }
        }
        if (CollectionUtils.isNotEmpty(toUpdateList)) {
            LOGGER.info("JdFirstTimeRefreshThread.toUpdateList.id = {}, JdFirstTimeRefreshThread.toUpdateList.size = {}",toUpdateList.stream().map(x->x.getId()).collect(Collectors.toList()), toUpdateList.size() );
            logisticsInfoMapper.batchUpdateFisrtInfoTime(toUpdateList);
        }
        countDownLatch.countDown();
    }

    private Date stringToDate(String date, String parttern) {
        Date myDate = null;
        if (date != null) {
            try {
                SimpleDateFormat simpleDateFormat = new SimpleDateFormat(parttern);
                myDate = simpleDateFormat.parse(date);
            } catch (Exception e) {
            }
        }
        return myDate;
    }


    private String parseFirstInfoTime(List<KuaiDaoYunKLogisticsEntity> list, String logisticsCompanyCode) {
        list = list.stream().sorted(Comparator.comparing(x -> x.TrackDate)).collect(Collectors.toList());
        for (KuaiDaoYunKLogisticsEntity entity : list) {
            if (logisticsCompanyCode.equals("jd")) {
                if (entity.TrackStatus.contains("揽收完成")
                        || entity.TrackStatus.contains("货物已交付京东物流")
                        || entity.TrackStatus.contains("打包完成")
                        || entity.TrackStatus.contains("分拣完成")
                        ) {
                    return entity.TrackDate;
                }
            } else if (!logisticsCompanyCode.equals("jd")) {
                if (entity.ShortStatus.contains("收件")) {
                    return entity.TrackDate;
                }
            }
        }
        return "";
    }
}
